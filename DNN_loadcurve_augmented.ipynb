{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5260a06",
   "metadata": {},
   "source": [
    "# DNN Augmentation — Section 0 & Load-Curve Dataset\n",
    "**说明 / Notes：** 在**大致保留原 ipynb 内容**的前提下，新增本节用于：  \n",
    "1) 统一放置可控参数（epochs、网络层数、采样数量等）；  \n",
    "2) 随机生成 100 个 `(x, y)` pair（可类比负荷曲线：`x=时间(小时)`，`y=标幺负荷`）；  \n",
    "3) 自动将 70%/30% 数据划分为训练/测试；  \n",
    "4) 使用 Keras DNN 拟合（保留原来 notebook 的主体内容在后面）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724897a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Section 0: Settings =========\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Reproducibility\n",
    "RNG_SEED = 42\n",
    "\n",
    "# Data settings\n",
    "N_SAMPLES = 100           # 随机采样数量\n",
    "TRAIN_RATIO = 0.70        # 训练/测试比例\n",
    "NOISE_STD = 0.04          # 噪声强度 (per unit)\n",
    "\n",
    "# Function type for y = f(x)\n",
    "# 选项: \"sin\", \"cos\", \"exp\", \"poly\", \"linear\", \"custom\"\n",
    "FUNC_TYPE = \"sin\"\n",
    "\n",
    "# If FUNC_TYPE == \"custom\", define it here as a python lambda function of x\n",
    "# 例如：lambda x: 0.5 + 0.3*np.sin(2*np.pi*x/24) + 0.2*np.exp(-0.2*(x-18)**2)\n",
    "CUSTOM_FUNC = lambda x: 0.5 + 0.3*np.sin(2*np.pi*(x-6)/24) + 0.25*np.exp(-0.5*((x-19)/2.5)**2)\n",
    "\n",
    "# DNN (Keras) settings\n",
    "EPOCHS = 800\n",
    "BATCH_SIZE = 16\n",
    "INPUT_DIM = 1\n",
    "HIDDEN_LAYERS = [64, 64]\n",
    "OUTPUT_DIM = 1\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "# Paths to save artifacts\n",
    "OUT_DIR = Path(\"/mnt/data\")\n",
    "CSV_PATH = OUT_DIR / \"load_pairs_100.csv\"\n",
    "MODEL_PATH = OUT_DIR / \"keras_dnn_load_model.h5\"\n",
    "HISTORY_PATH = OUT_DIR / \"keras_dnn_history.npy\"\n",
    "METRICS_PATH = OUT_DIR / \"keras_dnn_metrics.json\"\n",
    "\n",
    "print(\"Section 0 settings loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d235670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Section 1: Generate (x, y) pairs =========\n",
    "rng = np.random.default_rng(RNG_SEED)\n",
    "\n",
    "def pick_range_by_func(func_type: str):\n",
    "    if func_type in (\"sin\", \"cos\"):\n",
    "        return (0.0, 2*np.pi)         # radians domain for trig by default\n",
    "    elif func_type == \"exp\":\n",
    "        return (0.0, 10.0)\n",
    "    elif func_type == \"poly\":\n",
    "        return (-3.0, 3.0)\n",
    "    elif func_type == \"linear\":\n",
    "        return (0.0, 24.0)            # hours\n",
    "    elif func_type == \"custom\":\n",
    "        return (0.0, 24.0)\n",
    "    else:\n",
    "        return (0.0, 24.0)\n",
    "\n",
    "def base_function(x, func_type: str):\n",
    "    if func_type == \"sin\":\n",
    "        return np.sin(x)\n",
    "    if func_type == \"cos\":\n",
    "        return np.cos(x)\n",
    "    if func_type == \"exp\":\n",
    "        return np.exp(0.2*x) / np.exp(0.2*10.0)  # normalized to ~[e^0, e^2]→[~0.135,1]; scaled by division\n",
    "    if func_type == \"poly\":\n",
    "        return 0.1*x**3 - 0.2*x**2 + 0.3*x + 0.6\n",
    "    if func_type == \"linear\":\n",
    "        # daily load-like linear baseline (gently increasing daytime)\n",
    "        return 0.4 + 0.03*x\n",
    "    if func_type == \"custom\":\n",
    "        return CUSTOM_FUNC(x)\n",
    "    # default: simple daily load-like curve\n",
    "    return 0.6 + 0.2*np.sin(2*np.pi*(x-6)/24) + 0.35*np.exp(-0.5*((x-8)/2.0)**2) + 0.5*np.exp(-0.5*((x-19)/2.5)**2)\n",
    "\n",
    "xmin, xmax = pick_range_by_func(FUNC_TYPE)\n",
    "x = rng.uniform(xmin, xmax, size=N_SAMPLES)\n",
    "x = np.sort(x)\n",
    "\n",
    "# Build \"per-unit load-like\" y with noise; if FUNC_TYPE is trig/linear/custom with hour meaning,\n",
    "# we also clip to [0, 1.2] for realism.\n",
    "y_clean = base_function(x, FUNC_TYPE)\n",
    "noise = rng.normal(0.0, NOISE_STD, size=N_SAMPLES)\n",
    "y = y_clean + noise\n",
    "if FUNC_TYPE in (\"linear\", \"custom\"):\n",
    "    y = np.clip(y, 0.0, 1.2)\n",
    "\n",
    "# Save dataset\n",
    "df = pd.DataFrame({\"x\": x, \"y\": y, \"func\": FUNC_TYPE})\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(\"Saved dataset to:\", CSV_PATH)\n",
    "\n",
    "# Quick plot\n",
    "plt.figure()\n",
    "plt.scatter(x, y, s=20, label=\"samples\")\n",
    "plt.xlabel(\"x (hour or unit domain)\")\n",
    "plt.ylabel(\"y (per unit)\")\n",
    "plt.title(f\"Random {N_SAMPLES} (x, y) samples — {FUNC_TYPE}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Section 2: Train/Test split (70% / 30%) =========\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = x.reshape(-1, 1).astype(\"float32\")\n",
    "Y = y.reshape(-1, 1).astype(\"float32\")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, train_size=TRAIN_RATIO, random_state=RNG_SEED\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \" Test size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c9efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Section 3: DNN (Keras) training =========\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.random.set_seed(RNG_SEED)\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Input(shape=(INPUT_DIM,)))\n",
    "for h in HIDDEN_LAYERS:\n",
    "    model.add(layers.Dense(h, activation=\"relu\"))\n",
    "model.add(layers.Dense(OUTPUT_DIM, activation=\"linear\"))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=opt, loss=\"mse\", metrics=[\"mae\"])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Save model and history\n",
    "model.save(MODEL_PATH)\n",
    "np.save(HISTORY_PATH, history.history, allow_pickle=True)\n",
    "\n",
    "# Evaluate\n",
    "loss, mae = model.evaluate(X_test, Y_test, verbose=0)\n",
    "metrics = {\"test_mse\": float(loss), \"test_mae\": float(mae)}\n",
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Saved model to:\", MODEL_PATH)\n",
    "print(\"Saved history to:\", HISTORY_PATH)\n",
    "print(\"Saved metrics to:\", METRICS_PATH)\n",
    "print(\"Test metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Section 4: Visualization of Fit =========\n",
    "# Predict on dense grid for a smooth curve\n",
    "t_dense = np.linspace(x.min(), x.max(), 400, dtype=\"float32\").reshape(-1, 1)\n",
    "y_pred_dense = model.predict(t_dense, verbose=0).flatten()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t_dense.flatten(), y_pred_dense, label=\"DNN prediction\")\n",
    "plt.scatter(x, y, s=20, label=\"samples\")\n",
    "plt.xlabel(\"x (hour or unit domain)\")\n",
    "plt.ylabel(\"y (per unit)\")\n",
    "plt.title(\"Keras DNN Fit vs. Samples\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "# Import necessary libraries for numerical computing, deep learning, and plotting\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06039cad",
   "metadata": {},
   "source": [
    "## 1. Generate Training Data\n",
    "\n",
    "We aim to approximate the function **f(x) = sin(x)** using a simple Deep Neural Network (DNN).  \n",
    "First, we create 100 evenly spaced points in the range \\([0, 2\\pi]\\) and compute their sine values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data: x in [0, 2π], y = sin(x)\n",
    "x_train = np.linspace(0, 2 * np.pi, 1028).reshape(-1, 1)\n",
    "y_train = np.sin(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890cf47",
   "metadata": {},
   "source": [
    "## 2. Define the DNN Model\n",
    "\n",
    "We use TensorFlow/Keras to build a feedforward neural network with:\n",
    "- An input layer that takes scalar values (shape = 1)\n",
    "- Two hidden layers with 32 neurons and ReLU activation\n",
    "- A linear output layer that outputs a single value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef021942",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=(1,)),  # Input layer\n",
    "    layers.Dense(32, activation='relu'),                    # Hidden layer\n",
    "    layers.Dense(1, activation='linear')                    # Output layer\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d514b4",
   "metadata": {},
   "source": [
    "## 3. Compile the Model\n",
    "\n",
    "We compile the model using:\n",
    "- **Adam optimizer** for efficient training\n",
    "- **Mean Squared Error (MSE)** as the loss function\n",
    "- **Mean Absolute Error (MAE)** as an additional evaluation metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a71653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75db9d",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "We train the model on the generated data for 300 epochs with a batch size of 16.\n",
    "Verbose is set to 0 to suppress output during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b88cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=300, batch_size=16, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912c1ce",
   "metadata": {},
   "source": [
    "## 5. Test the Model\n",
    "\n",
    "We generate the same range of input values for testing and compare:\n",
    "- The **true values** of \\( \\sin(x) \\)\n",
    "- The **predicted values** from the trained DNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61449d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(0, 2 * np.pi, 100).reshape(-1, 1)\n",
    "y_true = np.sin(x_test)\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088dc6ef",
   "metadata": {},
   "source": [
    "## 6. Plot the Results\n",
    "\n",
    "We visualize how well the DNN approximates the sine function:\n",
    "- **Blue solid line**: True function \\( \\sin(x) \\)\n",
    "- **Red dashed line**: DNN-predicted output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_test, y_true, 'b-', label='True f(x) = sin(x)')\n",
    "plt.plot(x_test, y_pred, 'r--', label='Predicted by DNN')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('DNN Approximation of f(x) = sin(x)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
