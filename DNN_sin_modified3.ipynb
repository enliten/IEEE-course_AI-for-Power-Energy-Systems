{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6ac49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports ---\n",
    "# Import necessary libraries for numerical computing, deep learning, and plotting\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88de234",
   "metadata": {},
   "source": [
    "## 0. Initial Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc8098",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Initial Controls ====\n",
    "\n",
    "# Function choice: one of {\"sin\", \"cos\", \"exp\", \"poly3\", \"custom\"}\n",
    "FUNC_TYPE = \"sin\"\n",
    "\n",
    "# For poly3, coefficients for y = a*x^3 + b*x^2 + c*x + d\n",
    "POLY3_COEFFS = {\"a\": 0.1, \"b\": -0.2, \"c\": 0.3, \"d\": 0.0}\n",
    "\n",
    "# For custom, define a lambda function\n",
    "CUSTOM_FUNC = lambda x: x\n",
    "\n",
    "# Sampling number (was hardcoded as 1028 before)\n",
    "N_SAMPLES = 1028\n",
    "\n",
    "# Model hyperparameters (keep original values)\n",
    "EPOCHS = 300\n",
    "INPUT_SIZE = 1\n",
    "HIDDEN_LAYERS = [64, 64]\n",
    "OUTPUT_SIZE = 1\n",
    "\n",
    "print(\"Initial settings loaded.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06039cad",
   "metadata": {},
   "source": [
    "## 1. Generate Training Data\n",
    "\n",
    "We aim to approximate the function **f(x) = sin(x)** using a simple Deep Neural Network (DNN).  \n",
    "First, we create 100 evenly spaced points in the range \\([0, 2\\pi]\\) and compute their sine values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def make_function(func_type: str):\n",
    "    if func_type == \"sin\":\n",
    "        return np.sin, (0, 2*np.pi)\n",
    "    if func_type == \"cos\":\n",
    "        return np.cos, (0, 2*np.pi)\n",
    "    if func_type == \"exp\":\n",
    "        return np.exp, (0, 10)\n",
    "    if func_type == \"poly3\":\n",
    "        a, b, c, d = POLY3_COEFFS[\"a\"], POLY3_COEFFS[\"b\"], POLY3_COEFFS[\"c\"], POLY3_COEFFS[\"d\"]\n",
    "        return (lambda x: a*x**3 + b*x**2 + c*x + d), (-3, 3)\n",
    "    if func_type == \"custom\":\n",
    "        return CUSTOM_FUNC, (-5, 5)\n",
    "    raise ValueError(f\"Unknown FUNC_TYPE: {func_type}\")\n",
    "\n",
    "f, (x_min, x_max) = make_function(FUNC_TYPE)\n",
    "\n",
    "# Use N_SAMPLES instead of fixed 1028\n",
    "x_train = np.linspace(x_min, x_max, N_SAMPLES).reshape(-1, 1)\n",
    "y_train = f(x_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a890cf47",
   "metadata": {},
   "source": [
    "## 2. Define the DNN Model\n",
    "\n",
    "We use TensorFlow/Keras to build a feedforward neural network with:\n",
    "- An input layer that takes scalar values (shape = 1)\n",
    "- Two hidden layers with 32 neurons and ReLU activation\n",
    "- A linear output layer that outputs a single value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef021942",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Build model using variables from Section 0\n",
    "model = keras.Sequential()\n",
    "# Input layer\n",
    "model.add(layers.Dense(HIDDEN_LAYERS[0], activation='relu', input_shape=(INPUT_SIZE,)))\n",
    "# Hidden layers\n",
    "for h in HIDDEN_LAYERS[1:]:\n",
    "    model.add(layers.Dense(h, activation='relu'))\n",
    "# Output layer\n",
    "model.add(layers.Dense(OUTPUT_SIZE, activation='linear'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d514b4",
   "metadata": {},
   "source": [
    "## 3. Compile the Model\n",
    "\n",
    "We compile the model using:\n",
    "- **Adam optimizer** for efficient training\n",
    "- **Mean Squared Error (MSE)** as the loss function\n",
    "- **Mean Absolute Error (MAE)** as an additional evaluation metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a71653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75db9d",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "We train the model on the generated data for 300 epochs with a batch size of 16.\n",
    "Verbose is set to 0 to suppress output during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b88cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model using parameters from Section 0\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=16,\n",
    "                    verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912c1ce",
   "metadata": {},
   "source": [
    "## 5. Test the Model\n",
    "\n",
    "We generate the same range of input values for testing and compare:\n",
    "- The **true values** of \\( \\sin(x) \\)\n",
    "- The **predicted values** from the trained DNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61449d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate test data based on the same function setting\n",
    "f, (x_min, x_max) = make_function(FUNC_TYPE)\n",
    "x_test = np.linspace(x_min, x_max, 100).reshape(-1, 1)\n",
    "y_true = f(x_test)\n",
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088dc6ef",
   "metadata": {},
   "source": [
    "## 6. Plot the Results\n",
    "\n",
    "We visualize how well the DNN approximates the sine function:\n",
    "- **Blue solid line**: True function \\( \\sin(x) \\)\n",
    "- **Red dashed line**: DNN-predicted output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d3e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_test, y_true, 'b-', label='True f(x) = sin(x)')\n",
    "plt.plot(x_test, y_pred, 'r--', label='Predicted by DNN')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('DNN Approximation of f(x) = sin(x)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
